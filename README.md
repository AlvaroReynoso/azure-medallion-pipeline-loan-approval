# ğŸ”· Pipeline Azure Modelo MedallÃ³n â€“ Datos de AprobaciÃ³n de PrÃ©stamos (EspaÃ±ol)

Este proyecto implementa un pipeline ETL completo de punta a punta utilizando la **arquitectura MedallÃ³n (Bronce, Plata, Oro)** en Azure, procesando un dataset de solicitudes de prÃ©stamos bancarios.

 **Objetivo**: Limpiar y preparar datos crudos de aplicaciones de prÃ©stamos para generar insights como tasas de aprobaciÃ³n, anÃ¡lisis de ingresos y segmentaciÃ³n de solicitantes.

ğŸ”§ **TecnologÃ­as Utilizadas**:
- **Azure Data Factory**: OrquestaciÃ³n del pipeline
- **Azure Databricks**: TransformaciÃ³n de datos con PySpark
- **Delta Lake**: Formato de almacenamiento escalable
- **Azure Data Lake Storage Gen2**: Almacenamiento de datos
- **Power BI** *(opcional)*: VisualizaciÃ³n de insights de negocio

ğŸ“ **Estructura del Pipeline**:
1. **Capa Bronce**: Ingesta de datos crudos desde archivo CSV.
2. **Capa Plata**: Limpieza, formateo y tipado de datos.
3. **Capa Oro**: Agregaciones y mÃ©tricas clave listas para anÃ¡lisis.

ğŸ“Œ **Notebooks Incluidos**:
- `ETL_databank_loans_config`: ConfiguraciÃ³n de montado y rutas
- `ETL_databank_loans_bronce`: Lectura del CSV crudo y guardado en Delta y CSV
- `ETL_databank_loans_plata`: Limpieza y estandarizaciÃ³n del dataset
- `ETL_databank_loans_oro`: GeneraciÃ³n de KPIs como tasas de aprobaciÃ³n

ğŸ§  Habilidades:
- IngenierÃ­a de Datos en Azure
- Delta Lake y arquitectura MedallÃ³n
- PySpark y orquestaciÃ³n de pipelines

Descripcion: En este pipeline medallon se busca ingerir datos desde un archivo .csv almacenado en Data Lake, luego en la capa "Bronce" se busca transformar parcialmente las estructuras de columnas crudas (raw estructured)  para crear un modelo de delta table crudo (raw) y almacenar .parquet y .csv, en capa plata se busco limpiar datos insconsistentes y transformar tipos de datos para un manejo correcto.
Finalmente en la capa "oro" se busca crear modelos de agrupacion, porcentajes y promedios para posteriormente preparar KPIs.
Todo se manejo con un sistema de almacenamiento ordenado y creando tres directorios por capa. 



# Azure Medallion Pipeline â€“ Loan Approval Data (English)

This project implements a complete end-to-end ETL pipeline using the **Medallion architecture (Bronze, Silver, Gold)** on Azure, processing a bank loan approval dataset.

**Goal**: Clean and prepare raw loan application data to generate insights such as approval rates, income analysis, and applicant segmentation.

ğŸ”§ **Tools Used**:
- Azure Data Factory: Orchestration of pipeline
- Azure Databricks: Data transformation with PySpark
- Delta Lake: Scalable storage format
- Azure Data Lake Storage Gen2: Data storage
- Power BI (optional): Visualize business insights

ğŸ“ **Pipeline Structure**:
1. **Bronze Layer**: Raw data ingestion from CSV.
2. **Silver Layer**: Data cleaning, formatting, and type casting.
3. **Gold Layer**: Aggregations and KPIs ready for analysis.

ğŸ“Œ Notebooks Included:
- `ETL_databank_loans_config`: Mounts and paths configuration
- `ETL_databank_loans_bronce`: Reads raw CSV and stores Delta & CSV
- `ETL_databank_loans_plata`: Cleans and standardizes the dataset
- `ETL_databank_loans_oro`: Generates approval rate KPIs

ğŸ§  Skills:
- Data Engineering with Azure
- Delta Lake and Medallion Architecture
- PySpark and pipeline orchestration

**Description**: This medallion pipeline ingests data from a .csv file stored in a Data Lake. The Bronze layer partially transforms the raw column structures to create a raw delta table model and store .parquet and .csv files. The Silver layer cleans inconsistent data and transforms data types for proper management.
Finally, the Gold layer creates clustering models, percentages, and averages to later prepare KPIs.
Everything is managed with an organized storage system, creating three directories per layer.

ğŸ” Requisitos previo: 
Se creo un secret Scope en databricks secrets para alojar una llave o key.
Con este mecanismo, Databricks puede conectarse a tu contenedor sin necesidad de poner la clave en el cÃ³digo y exponerla.


Imagenes / Images
![PIPE](https://github.com/user-attachments/assets/daa9852b-fd1d-4f54-af7f-68c0cbfbe5ea)

![check databricks](https://github.com/user-attachments/assets/07730931-b891-4eb8-a63a-626fd57ae91e)

![capas 3](https://github.com/user-attachments/assets/44bb79da-7907-4b81-8747-96baf5dab7c0)



